{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "To4RcII2inSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779b845f-91d2-4ca6-d336-ad2fa94528c6"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "import torchvision.transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm, tnrange\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import copy\n",
        "\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "CUDA = torch.cuda.is_available()\n",
        "CUDA_DEVICE = 0\n",
        "if CUDA:\n",
        "    device='cuda:1'\n",
        "else:\n",
        "    device='cpu'\n",
        "torch.cuda.is_available()\n",
        "\n",
        "CUDA = torch.cuda.is_available()\n",
        "CUDA_DEVICE = 0\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base='drive/MyDrive'\n",
        "except:\n",
        "    if torch.cuda.device_count()>1:\n",
        "        base='.'\n",
        "    else:\n",
        "        base='Google Drive'\n",
        "\n",
        "if CUDA:\n",
        "    device='cuda:1'\n",
        "else:\n",
        "    device='cpu'\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPBnJ67MrIEn"
      },
      "source": [
        "class RBM(nn.Module):\n",
        "    def __init__(self, n_vis, n_hid):\n",
        "        \"\"\"Create a RBM.\"\"\"\n",
        "        super(RBM, self).__init__()\n",
        "        self.v_bias = nn.Parameter(torch.zeros(1, n_vis).to(device))\n",
        "        self.h_bias = nn.Parameter(torch.zeros(1, n_hid).to(device))\n",
        "        self.Weight = nn.Parameter(std*torch.randn(n_hid, n_vis).to(device))\n",
        "\n",
        "    def v2h(self, v):\n",
        "        return torch.sigmoid(F.linear(v, self.Weight, self.h_bias)).bernoulli()\n",
        "\n",
        "    def h2v(self, h):\n",
        "        return torch.sigmoid(F.linear(h, self.Weight.t(), self.v_bias)).bernoulli()\n",
        "    \n",
        "    def Fv(self, v):\n",
        "        v_term = torch.matmul(v, self.v_bias.t()).view(len(v))\n",
        "        h_term = torch.sum(F.softplus(F.linear(v, self.Weight, self.h_bias)), dim=1)\n",
        "        return -h_term -v_term\n",
        "\n",
        "    def energy(self, v, h):\n",
        "        v=v.bernoulli()\n",
        "        h=h.bernoulli()\n",
        "        return -torch.matmul(v, self.v_bias.t())-torch.matmul(torch.matmul(v, self.Weight.t()),h.t())-torch.matmul(h, self.h_bias.t())\n",
        "\n",
        "    def forward(self, v):\n",
        "\n",
        "        return v.bernoulli()\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset): \n",
        "    def __init__(self, dataset):\n",
        "        data_x = dataset\n",
        "        self.x_data = data_x\n",
        "#         self.y_data = data_y\n",
        "\n",
        "    # 총 데이터의 개수를 리턴\n",
        "    def __len__(self): \n",
        "        return len(self.x_data)\n",
        "    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
        "    def __getitem__(self, idx): \n",
        "        x = torch.FloatTensor(self.x_data[idx])\n",
        "#         y = torch.FloatTensor([self.y_data[idx]])\n",
        "        return x\n",
        "\n",
        "def data_to_loader(fullconfigs):\n",
        "    fulldata=CustomDataset(fullconfigs)\n",
        "    full_dataset = fulldata\n",
        "    full_loader = torch.utils.data.DataLoader(full_dataset, batch_size)\n",
        "    return full_loader\n",
        "\n",
        "def train_and_get_data(n_hid, model, lr):\n",
        "    rbm=RBM(n_vis, n_hid)\n",
        "    train_loss_list=[]\n",
        "#     train_op = optim.Adam(rbm.parameters(), lr)\n",
        "    train_op = optim.SGD(rbm.parameters(), lr, momentum=0.9)\n",
        "    rbm.train()\n",
        "    train_loss_list=[]\n",
        "    model_list=[]\n",
        "    for epoch in tnrange(n_epochs):\n",
        "        Fv=torch.dot(rbm.Fv(full_configs1).double(), Pv)\n",
        "        FE=-torch.log(torch.sum(torch.exp(-rbm.Fv(full_configs1))))\n",
        "        train_loss = Fv-FE\n",
        "        train_op.zero_grad()\n",
        "        train_loss.backward()\n",
        "        train_op.step()\n",
        "        GE=Fv-FE-S\n",
        "        if epoch in epoch_to_save:\n",
        "            train_loss_list.append(float((train_loss-S).detach().cpu().numpy()))\n",
        "            model_list.append(copy.deepcopy(rbm.cpu().state_dict()))\n",
        "            print('epoch={epoch}, GE={GE}'.format(epoch=epoch, GE=GE))\n",
        "    return model_list, train_loss_list\n",
        "\n",
        "def CM_model(models):\n",
        "    new_v_bias=0; new_h_bias=0; new_Weight=0\n",
        "    for m in range(10):\n",
        "        new_v_bias+=models[str(m)][-1]['v_bias']/10\n",
        "        new_h_bias+=models[str(m)][-1]['h_bias']/10\n",
        "        new_Weight+=models[str(m)][-1]['Weight']/10\n",
        "    return {'v_bias':new_v_bias, 'h_bias':new_h_bias, 'Weight':new_Weight}  \n",
        "\n",
        "def mean_Fv(Q_m, v0):\n",
        "    value=0\n",
        "    for m in range(10):\n",
        "        rbm=RBM(n_vis, n_hid, k=1)\n",
        "        rbm.load_state_dict(Q_m[str(m)])\n",
        "        value+=rbm.Fv(v0)/10\n",
        "    return value\n",
        "\n",
        "\n",
        "def get_next_states(state0):\n",
        "    occupied_spot=[]\n",
        "    use_alpha=False\n",
        "    use_beta=False\n",
        "\n",
        "    for i in range(1,len(state0)+1):\n",
        "        if state0[-i]=='1':\n",
        "            occupied_spot.append(i)\n",
        "    # print(occupied_spot)\n",
        "    movable_spot=[]\n",
        "    movable_count=0\n",
        "    for j in range(len(occupied_spot)):\n",
        "        if occupied_spot[j]+1 not in occupied_spot:\n",
        "            movable_spot.append(occupied_spot[j])\n",
        "            movable_count+=1\n",
        "    # print(movable_count)\n",
        "\n",
        "    next_states=[]\n",
        "    for k in range(len(movable_spot)):\n",
        "        state1=state0\n",
        "        state1=list(state1)\n",
        "        state1[-movable_spot[k]]='0'\n",
        "        try:\n",
        "            state1[-movable_spot[k]-1]='1'\n",
        "            state1=''.join(state1[e] for e in range(len(state1)))\n",
        "        except:\n",
        "            # An outflow of a partible.\n",
        "            use_beta=True\n",
        "        state1=''.join(state1[e] for e in range(len(state1)))\n",
        "        next_states.append(state1)\n",
        "        # An inflow of a new particle.\n",
        "    if state0[-1]=='0':\n",
        "        use_alpha=True\n",
        "        state1=state0\n",
        "        state1=list(state1)\n",
        "        state1[-1]='1'\n",
        "        state1=''.join(state1[e] for e in range(len(state1)))\n",
        "        next_states.append(state1)\n",
        "    use_alpha_beta=[use_alpha, use_beta]\n",
        "\n",
        "    factor_next_states={}\n",
        "    for l in range(len(next_states)):\n",
        "        try:\n",
        "            factor_next_states[str(next_states[l])]=1/(len(next_states)-use_beta-use_alpha)\n",
        "            # print('aa')\n",
        "            # print(1/(len(next_states-use_alpha-use_beta)))\n",
        "        except:\n",
        "            None\n",
        "\n",
        "        if int(list(str2arr(state0)-str2arr(next_states[l]))[-1])==-1:\n",
        "            factor_next_states[str(next_states[l])]=alpha\n",
        "        if int(list(str2arr(state0)-str2arr(next_states[l]))[0])==1:\n",
        "            factor_next_states[str(next_states[l])]=beta\n",
        "    return next_states, factor_next_states\n",
        "\n",
        "def check_boundary(state0):\n",
        "    use_alpha=False\n",
        "    use_beta=False\n",
        "    if state0[0]=='1':\n",
        "        use_beta=True\n",
        "    if state0[-1]=='0':\n",
        "        use_alpha=True\n",
        "\n",
        "    return use_alpha, use_beta\n",
        "\n",
        "def dec2bin(integer, n_hid):\n",
        "    string=bin(int(integer))[2:]\n",
        "    list0=[int(d) for d in string]\n",
        "    while len(list0)<n_hid:\n",
        "        list0=[0]+list0\n",
        "    a=np.array([list0])[0]\n",
        "    b=''.join(str(e) for e in a)\n",
        "    return b\n",
        "\n",
        "def arr2str(array0):\n",
        "    a=np.array([array0])[0]\n",
        "    b=''.join(str(e) for e in a)\n",
        "    return b\n",
        "\n",
        "\n",
        "def str2arr(str0):\n",
        "    b=[int(str0[i]) for i in range(len(str0))]\n",
        "    b=np.array(b)\n",
        "    return b\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_ab(config0):\n",
        "    a=config0.count(0)\n",
        "    b=config0.count(1)\n",
        "    return a,b\n",
        "\n",
        "\n",
        "def seperate(config_list):\n",
        "    for j in range(len(config_list)):\n",
        "        if '01' in arr2str(config_list[j]):\n",
        "            config0=config_list[j]\n",
        "            break\n",
        "        else:\n",
        "            None\n",
        "    try:\n",
        "        for i in range(len(config0)-1):\n",
        "            if config0[i]==0 and config0[i+1]==1:\n",
        "                config_list.append(del_comp(config0, i))\n",
        "                config_list.append(del_comp(config0, i+1))\n",
        "                config_list.remove(config0)\n",
        "                break\n",
        "            else:\n",
        "                None\n",
        "    except:\n",
        "        None\n",
        "def check(config_list):\n",
        "    TF='01'\n",
        "    for i in range(len(config_list)):\n",
        "        if '01' in arr2str(config_list[i]):\n",
        "            TF=True\n",
        "            break\n",
        "        else:\n",
        "            TF=False\n",
        "    return TF\n",
        "\n",
        "def del_comp(list0, i):\n",
        "    list1=list0.copy()\n",
        "    del list1[i]\n",
        "    return list1\n",
        "\n",
        "def opS(list0):\n",
        "    config_list=[list0]\n",
        "    while check(config_list):\n",
        "   #     print(config_list)\n",
        "        seperate(config_list)\n",
        "    return config_list\n",
        "\n",
        "def get_ideal_dist():\n",
        "    dist={}\n",
        "    for i in range(2**Nv):\n",
        "        flist=opS(list(str2arr(dec2bin(i,Nv))))    \n",
        "        f=0\n",
        "        for j in range(len(flist)):\n",
        "            a,b=get_ab(flist[j])\n",
        "            f+=((1/alpha)**a)*((1/beta)**b)\n",
        "\n",
        "        dist[dec2bin(i,Nv)]=f\n",
        "    s=np.sum(list(dist.values()))\n",
        "    for i in range(2**Nv):\n",
        "        dist[dec2bin(i,Nv)]=dist[dec2bin(i,Nv)]/s\n",
        "    return dist\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TASEP_dynamics(state0, n_sample):\n",
        "    state_list=[]\n",
        "    for step in range(n_sample):\n",
        "        r0=np.random.randint(0,N+1)\n",
        "        if r0==0:\n",
        "            if state0[-1]=='0':\n",
        "                if np.random.rand()<alpha:\n",
        "                    state0=str2arr(state0)\n",
        "                    state0[-1]='1'\n",
        "                else:None\n",
        "            else:None\n",
        "        elif r0==N:\n",
        "            if state0[0]=='1':\n",
        "                if np.random.rand()<beta:\n",
        "                    state0=str2arr(state0)\n",
        "                    state0[0]='0'\n",
        "                else:None\n",
        "            else:None\n",
        "        else:\n",
        "            if state0[-r0]=='1' and state0[-r0-1]=='0':\n",
        "                state0=str2arr(state0)\n",
        "                state0[-r0]='0'\n",
        "                state0[-r0-1]='1'\n",
        "        state0=arr2str(state0)\n",
        "        # state0=str2arr(state0)\n",
        "        state_list.append(state0)\n",
        "    \n",
        "    # staet counting\n",
        "    dist={}\n",
        "    for i in range(len(state_list)):\n",
        "        dist[state_list[i]]=0\n",
        "    for i in range(len(state_list)):\n",
        "        dist[state_list[i]]+=1\n",
        "    observed=list(dist.keys())\n",
        "    for i in range(len(observed)):\n",
        "        \n",
        "        dist[observed[i]]=dist[observed[i]]/len(state_list)\n",
        "        \n",
        "    for i in range(len(state_list)):\n",
        "        state_list[i]=torch.tensor(str2arr(state_list[i]))\n",
        "    return torch.stack(state_list).float()"
      ],
      "metadata": {
        "id": "OgJmwKzAEDvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu3QpRUBrIHD"
      },
      "source": [
        "# Hyper parameter들을 설정\n",
        "n_vis=9\n",
        "k=1\n",
        "lr=0.1\n",
        "std=0.5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=1\n",
        "n_vis=9\n",
        "N=n_vis\n",
        "Nv=n_vis\n",
        "std=0.1\n",
        "\n",
        "epoch_to_save=[2**i for i in range(17)]\n",
        "n_epochs=epoch_to_save[-1]+1\n",
        "torch.set_printoptions(precision=10)\n",
        "\n",
        "\n",
        "for alpha, beta in [[0.2,0.6],[0.3,0.5],[0.4,0.4]]:\n",
        "    # for beta in [0.4]:\n",
        "        prob_dict=get_ideal_dist()\n",
        "\n",
        "        sum=np.sum(list(prob_dict.values()))\n",
        "        for i in range(2**N):\n",
        "            config0=dec2bin(i, N)\n",
        "            prob_dict[config0]=prob_dict[config0]/sum\n",
        "\n",
        "        full_configs1=[]\n",
        "        full_configs2=[]\n",
        "        for i in range(2**N):\n",
        "            full_configs1.append(str2arr(dec2bin(i,N)))\n",
        "            full_configs2.append(str2arr(dec2bin(i,N))*2-1)\n",
        "        full_configs1=torch.tensor(full_configs1).float()\n",
        "        full_configs2=torch.tensor(full_configs2).float()\n",
        "\n",
        "        for n_hid in [1,2,3,4,6,8,12]:  \n",
        "            Nh=n_hid\n",
        "            Pv=torch.tensor(list(prob_dict.values()))\n",
        "            S=entropy(Pv)\n",
        "            # batch_size=int(vol/2)\n",
        "            dict_model={}\n",
        "            dict_GE={}\n",
        "            train_loader_list=[]; val_loader_list=[]\n",
        "\n",
        "            for m in range(10):\n",
        "                model0, loss=train_and_get_data(n_hid, 0, lr=lr)\n",
        "                dict_model[str(m)]=model0\n",
        "                dict_GE[str(m)]=loss\n",
        "            with open('{base}/TASEP/exact_state_dict/model_Nh={Nh}_alpha={alpha}_beta={beta}.pkl'.format(base=base, Nh=Nh, alpha=alpha, beta=beta), 'wb') as f:\n",
        "                pkl.dump(dict_model, f)\n",
        "            with open('{base}/TASEP/exact_loss/GE_Nh={Nh}_alpha={alpha}_beta={beta}.pkl'.format(base=base, Nh=Nh, alpha=alpha, beta=beta), 'wb') as f:\n",
        "                pkl.dump(dict_GE, f)"
      ],
      "metadata": {
        "id": "jDBd3uZBNf8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kx-P8t9rISQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEBRS4arIUQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}